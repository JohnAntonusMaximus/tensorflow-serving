# TensorFlow Serving For Production - TensorFlow Model Serving

[![Tensorflow](https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcT7b9ZDD7lMdkByT-f_RCAqSQYqnq_CpgD16IFrwfmUwWCmdt7H)](https://www.tensorflow.org/beta/guide/effective_tf2)

[![Colab](https://camo.githubusercontent.com/52feade06f2fecbf006889a904d221e6a730c194/68747470733a2f2f636f6c61622e72657365617263682e676f6f676c652e636f6d2f6173736574732f636f6c61622d62616467652e737667)](https://colab.research.google.com/github/JohnAntonusMaximus/tensorflow-serving/blob/master/Image_Classification_API_Using_TensorFlow_Serving.ipynb)

## Background

TensorFlow Serving is a flexible, high-performance serving system for machine learning models, designed for production environments. TensorFlow Serving makes it easy to deploy new algorithms and experiments, while keeping the same server architecture and APIs. TensorFlow Serving provides out-of-the-box integration with TensorFlow models, but can be easily extended to serve other types of models and data.

Detailed developer documentation on TensorFlow Serving :
https://www.tensorflow.org/tfx/guide/serving

						

## Approach

Using a convolutional neural network, we build, train, and evaluate an image classification model using the CIFAR10 dataset, and then serve it using TensorFlow Model Serving. 


# Links

* [KaizenTek](http://www.kaizentek.io) - IT Consulting & Cloud Professional Services 
